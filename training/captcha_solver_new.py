# -*- coding: utf-8 -*-
"""captcha-solver-new.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uo1_Zt3AVPzCLLVb3hZDrZjcqX_Ab1H-
"""

from zipfile import ZipFile

with ZipFile("samples.zip", 'r') as zObject:
    # Extracting all the members of the zip
    # into a specific location.
    zObject.extractall(path="")

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
import cv2
import numpy as np
import os
from PIL import Image
import kagglehub
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.cm as cm
import random
# import captcha

path = "."
print("Path to dataset files:", path)

labels_text =  [f"{path + '/samples/' + x} {x.replace('.png', '').replace('.jpg', '')}" for x in os.listdir(path + "/samples")]
# labels_text.remove("/root/.cache/kagglehub/datasets/fournierp/captcha-version-2-images/versions/2/samples/samples samples")

labels_text

class CaptchaDataset(Dataset):
    def __init__(self, image_dir, transform=None):
        """
        Args:
            image_dir (str): Directory with CAPTCHA images.
            label_file (str): File containing image labels (1 per line).
            transform (callable, optional): Optional transform to be applied on a sample.
        """
        self.image_dir = image_dir
        self.label_file = labels_text
        self.transform = transform
        self.images = []
        self.labels = []

        # Load image paths and corresponding labels
        for line in self.label_file:
            img_path, label = line.strip().split(' ')
            self.images.append(img_path)
            self.labels.append(label)

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_path = os.path.join(self.image_dir, self.images[idx])
        image = Image.open(img_path)
        label = self.labels[idx]

        # Apply any transformations
        if self.transform:
            image = self.transform(image)

        image = image.to("cuda")

        return image, label

class CaptchaCNN(nn.Module):
    def __init__(self, num_classes=36):
        super(CaptchaCNN, self).__init__()

        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)

        self.fc1 = nn.Linear(128 * 8 * 8, 1024)  # Flattening the convolutional output
        self.fc2 = nn.Linear(1024, 5 * num_classes)  # Output 5 classes for each character

        self.num_classes = num_classes

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = torch.max_pool2d(x, 2)  # Max pooling

        x = torch.relu(self.conv2(x))
        x = torch.max_pool2d(x, 2)

        x = torch.relu(self.conv3(x))
        x = torch.max_pool2d(x, 2)

        x = x.view(x.size(0), -1)  # Flatten

        x = torch.relu(self.fc1(x))
        x = self.fc2(x)

        # Split the output into 5 parts (for 5 characters)
        x = x.view(-1, 5, self.num_classes)

        return x

# Instantiate the model, loss function, and optimizer
model = CaptchaCNN(num_classes=36)  # Assuming we are using letters and digits (36 classes)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

model = model.to("cuda")

transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale
    transforms.Resize((64, 64)),  # Resize to a fixed size
    transforms.ToTensor(),  # Convert to a tensor
    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize pixel values
])

# Data loading
train_dataset = CaptchaDataset(image_dir=path, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

num_epochs = 1000

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for images, labels in train_loader:
        # One-hot encode the labels for 5 characters
        label_tensors = []
        for label in labels:
            label_tensor = torch.tensor([int(c, 36) for c in label], dtype=torch.long)
            label_tensor = label_tensor.to("cuda")
            label_tensors.append(label_tensor)
        label_tensors = torch.stack(label_tensors)

        # Zero the gradients
        optimizer.zero_grad()

        # Forward pass
        outputs = model(images)

        # Compute loss (for each character)
        loss = 0
        for i in range(5):
            loss += criterion(outputs[:, i, :], label_tensors[:, i])

        # Backward pass
        loss.backward()

        # Update weights
        optimizer.step()

        # Track the loss and accuracy
        running_loss += loss.item()
        _, predicted = torch.max(outputs, 2)  # Take the highest probability for each character
        correct += (predicted == label_tensors).sum().item()
        total += len(labels[0]) * 5  # 5 characters per image


    print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}")

model.eval()


chars = "123456789abcdefghijklmnopqrstuvwxyz"


with torch.no_grad():

    "/root/.cache/kagglehub/datasets/fournierp/captcha-version-2-images/versions/2/samples/MyGreatImage.png"
    #image = Image.open(path + "/samples/24pew.png")
    image = Image.open("./samples/3tkiz.png")
    image = transform(image).unsqueeze(0)  # Add batch dimension
    image = image.to("cuda")
    outputs = model(image)

    # Get the predicted characters for each position
    predicted_chars = []
    for i in range(5):
        _, predicted = torch.max(outputs[0, i, :], 0)
        predicted_char = str(predicted.item())
        predicted_chars.append(chars[int(predicted_char)-1])

    captcha_result = ''.join(predicted_chars)
    print(f"Predicted CAPTCHA: {captcha_result}")

torch.save(model.state_dict(), "theModelWeights")